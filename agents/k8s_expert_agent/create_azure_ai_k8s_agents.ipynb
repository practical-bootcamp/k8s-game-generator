{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings and create project client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import FileSearchTool, FilePurpose\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "SETTINGS_FILE = \"k8s_agent.yaml\"\n",
    "IMPORTED_FILES = \"k8s_files.txt\"\n",
    "IMPORTED_FILE_IDS = \"k8s_file_ids.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or reload the k8s vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded vector store: vs_PGrKdlx7jl46WkMm06i8gUAU\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "if os.path.exists(SETTINGS_FILE):\n",
    "    with open(SETTINGS_FILE, \"r\") as file:\n",
    "        settings = yaml.safe_load(file)\n",
    "    vector_store_id = settings[\"vector_store_id\"]\n",
    "    if vector_store_id is not None:    \n",
    "        vector_store = project_client.agents.get_vector_store(vector_store_id)\n",
    "        print(f\"Reloaded vector store: {vector_store.id}\")\n",
    "else:\n",
    "    # create a vector store with no file and wait for it to be processed\n",
    "    vector_store = project_client.agents.create_vector_store_and_poll(\n",
    "        data_sources=[], name=\"k8s_vector_store\"\n",
    "    )\n",
    "    print(f\"Created vector store, vector store ID: {vector_store.id}\")\n",
    "    # Save the vector store ID to k8s_agent.yaml\n",
    "\n",
    "    settings = {\"vector_store_id\": vector_store.id}\n",
    "\n",
    "    with open(SETTINGS_FILE, \"w\") as file:\n",
    "        yaml.dump(settings, file)\n",
    "    print(f\"Saved vector store ID to settings.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or reload the k8s agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k8s_expert_agent(vector_store_id: str):\n",
    "    print(\"This is k8s Azure AI Agent Service .......\")    \n",
    "    file_search_tool = FileSearchTool(vector_store_ids=[vector_store_id])\n",
    "\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        name=\"k8s-agent\",\n",
    "        instructions=\"You are a helpful agent for Kubernetes, capable of generating question and answer pairs to assist with Kubernetes-related inquiries.\",\n",
    "        tools=file_search_tool.definitions,\n",
    "        tool_resources=file_search_tool.resources,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded vector store: asst_ujCbHwxZvxUZrzPw8ku7RqXP\n",
      "Saved agent ID to settings.yaml\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(SETTINGS_FILE):\n",
    "    with open(SETTINGS_FILE, \"r\") as file:\n",
    "        settings = yaml.safe_load(file)\n",
    "    if \"agent_id\" in settings:\n",
    "        agent_id = settings[\"agent_id\"]       \n",
    "        agent = project_client.agents.get_agent(agent_id)\n",
    "        print(f\"Reloaded vector store: {agent.id}\")\n",
    "    else:\n",
    "        agent = create_k8s_expert_agent(vector_store.id)\n",
    "        print(f\"Created agent: {agent.id}\")\n",
    "        # Save the vector store ID to settings.yaml\n",
    "    settings[\"agent_id\"] = agent.id\n",
    "    with open(SETTINGS_FILE, \"w\") as file:\n",
    "        yaml.dump(settings, file)\n",
    "    print(f\"Saved agent ID to settings.yaml\")\n",
    "else:\n",
    "    ValueError(f\"{SETTINGS_FILE} file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file already exists: ../../data/k8s-website.zip\n",
      "Skipping download...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = \"../../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"Created directory: {data_dir}\")\n",
    "\n",
    "# URL for Kubernetes website repository\n",
    "url = \"https://github.com/dohsimpson/kubernetes-doc-pdf/archive/refs/heads/master.zip\"\n",
    "zip_path = os.path.join(data_dir, \"k8s-website.zip\")\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    print(f\"Zip file already exists: {zip_path}\")\n",
    "    print(\"Skipping download...\")\n",
    "else:\n",
    "    # Download the zip file with progress bar\n",
    "    print(f\"Downloading {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  # Raise exception for HTTP errors\n",
    "\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "    progress_bar = tqdm(total=total_size, unit=\"B\", unit_scale=True)\n",
    "\n",
    "    with open(zip_path, \"wb\") as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Extract the zip file\n",
    "    print(f\"Extracting {zip_path} to {data_dir}...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "    print(\n",
    "        f\"Successfully downloaded and extracted Kubernetes website repository to {data_dir}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_all_files(directory):\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "directory = os.path.join(data_dir, \"kubernetes-doc-pdf-master\", \"PDFs\")\n",
    "all_files = get_all_files(directory)\n",
    "print(f\"Total files found: {len(all_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_vector_store(file_path):    \n",
    "    vector_store_file = project_client.agents.upload_file_and_poll(file_path=file_path, purpose=FilePurpose.AGENTS)\n",
    "    return vector_store_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 6/6 [01:07<00:00, 11.23s/file]\n"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "import os\n",
    "\n",
    "stored_vector_store_files = []\n",
    "if os.path.exists(IMPORTED_FILES):\n",
    "    with open(IMPORTED_FILES, \"r\") as imported_files:\n",
    "        stored_vector_store_files = [line.strip() for line in imported_files.readlines()]\n",
    "        print(f\"Loaded {len(stored_vector_store_files)} files from {IMPORTED_FILES}\")\n",
    "\n",
    "all_files = [file_path for file_path in all_files if file_path not in stored_vector_store_files]\n",
    "\n",
    "vector_store_files = []\n",
    "with open(IMPORTED_FILE_IDS, \"w\") as imported_file_ids:\n",
    "    with open(IMPORTED_FILES, \"w\") as imported_files:\n",
    "        for file_path in tqdm.tqdm(all_files, desc=\"Uploading files\", unit=\"file\"):\n",
    "            vector_store_file = upload_files_to_vector_store(file_path)\n",
    "            vector_store_files.append(vector_store_file.id)\n",
    "            imported_files.write(f\"{file_path}\\n\")\n",
    "            imported_file_ids.write(f\"{vector_store_file.id} {file_path}\\n\")\n",
    "   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'file', 'id': 'assistant-JuDaFJGzqN1Avwwtqi5YYW', 'purpose': 'assistants', 'filename': 'Tutorials.pdf', 'bytes': 782577, 'created_at': 1741074048, 'status': 'processed', 'status_details': None}\n",
      "{'object': 'file', 'id': 'assistant-4Rb8C1gpvMCQiBXSXdJGMY', 'purpose': 'assistants', 'filename': 'Concepts.pdf', 'bytes': 3643479, 'created_at': 1741074037, 'status': 'processed', 'status_details': None}\n",
      "{'object': 'file', 'id': 'assistant-9sGDPt7bc6QveDn7TJ5gxA', 'purpose': 'assistants', 'filename': 'Setup.pdf', 'bytes': 479891, 'created_at': 1741074025, 'status': 'processed', 'status_details': None}\n",
      "{'object': 'file', 'id': 'assistant-X96h83LP58vcEyAEHrqnSx', 'purpose': 'assistants', 'filename': 'Tasks.pdf', 'bytes': 3950463, 'created_at': 1741074015, 'status': 'processed', 'status_details': None}\n",
      "{'object': 'file', 'id': 'assistant-MGA2BX9Y32PcmGBA7NGd4o', 'purpose': 'assistants', 'filename': 'kubectl-commands.pdf', 'bytes': 615154, 'created_at': 1741074004, 'status': 'processed', 'status_details': None}\n",
      "{'object': 'file', 'id': 'assistant-SB1qhoEhyHrgLqYhZ5Pj7f', 'purpose': 'assistants', 'filename': 'Reference.pdf', 'bytes': 9992684, 'created_at': 1741073993, 'status': 'processed', 'status_details': None}\n"
     ]
    }
   ],
   "source": [
    "files = project_client.agents.list_files()\n",
    "for d in files['data']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch created with ID: vsfb_ecf38816641f4ded9c023d88844fe438\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "for i in range(0, len(vector_store_files), batch_size):\n",
    "    batch_files = vector_store_files[i:i + batch_size]\n",
    "    batch = project_client.agents.create_vector_store_file_batch_and_poll(\n",
    "        vector_store_id=vector_store.id,\n",
    "        file_ids=batch_files\n",
    "    )\n",
    "    print(f\"Batch created with ID: {batch.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the k8s Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "\n",
    "message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"\"\"    \n",
    "               List out kubebernetes entities.\n",
    "            \"\"\",\n",
    ")\n",
    "# create and execute a run\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'msg_vfMtRWWqqb3ubf66GxgxW3fF', 'object': 'thread.message', 'created_at': 1741592418, 'assistant_id': 'asst_ujCbHwxZvxUZrzPw8ku7RqXP', 'thread_id': 'thread_Y2Xq6HSTQgAbRnqneems8fqb', 'run_id': 'run_2PJEEP5Uch3qwE9KliykenGm', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': 'Kubernetes consists of various entities that play vital roles in managing containerized applications. Below is a list of some key Kubernetes entities:\\n\\n### 1. Workload Resources\\n- **Pod**: A collection of one or more containers that share the same network namespace.\\n- **ReplicaSet**: Ensures that a specified number of pod replicas are running at any given time.\\n- **Deployment**: Manages the creation and updates of ReplicaSets and Pods in a declarative manner.\\n- **StatefulSet**: Designed for managing stateful applications, it provides guarantees about the ordering and uniqueness of Pods.\\n- **DaemonSet**: Ensures that a copy of a Pod runs on all or some nodes in the cluster.\\n- **Job**: Represents a one-time task that runs a Pod until completion.\\n- **CronJob**: Manages time-based jobs that run on a schedule.\\n\\n### 2. Service Resources\\n- **Service**: An abstract way to expose an application running on a set of Pods as a network service.\\n- **EndpointSlice**: Provides a link between Services and Pods for better scalability.\\n\\n### 3. Config and Storage Resources\\n- **ConfigMap**: An API object used to store non-confidential data in key-value pairs.\\n- **Secret**: Similar to ConfigMap but is specifically designed to hold sensitive data such as passwords or tokens.\\n- **PersistentVolume (PV)**: A piece of storage in the cluster that has been provisioned by an administrator.\\n- **PersistentVolumeClaim (PVC)**: A request for storage by a user.\\n\\n### 4. Policy Resources\\n- **NetworkPolicy**: Defines rules for how Pods can communicate with each other and with other network endpoints.\\n- **PodDisruptionBudget**: Specifies the minimum number of Pods that should be kept available during voluntary disruptions.\\n\\n### 5. Authentication and Authorization Resources\\n- **ServiceAccount**: An account for processes running in a Pod.\\n- **Role and ClusterRole**: Define access permissions for resources in a namespace (Role) or in the entire cluster (ClusterRole).\\n- **RoleBinding and ClusterRoleBinding**: Bind roles to users or service accounts to grant them permissions defined in the respective roles.\\n\\n### 6. Extend Resources\\n- **CustomResourceDefinition (CRD)**: Allows users to extend Kubernetes capabilities to create custom resources that are not part of the core Kubernetes API.\\n\\n### 7. Other Resources\\n- **Namespace**: A way to divide cluster resources between multiple users (via resource quota).\\n- **Event**: Records notable occurrences in the cluster.\\n\\nThese entities interact with each other to form a robust structure for deploying and managing applications in Kubernetes【4:1†source】【4:2†source】.', 'annotations': [{'type': 'file_citation', 'text': '【4:1†source】', 'start_index': 2582, 'end_index': 2594, 'file_citation': {'file_id': 'assistant-SB1qhoEhyHrgLqYhZ5Pj7f'}}, {'type': 'file_citation', 'text': '【4:2†source】', 'start_index': 2594, 'end_index': 2606, 'file_citation': {'file_id': 'assistant-4Rb8C1gpvMCQiBXSXdJGMY'}}]}}], 'attachments': [], 'metadata': {}},\n",
      " {'id': 'msg_spc5cziQCX1dwtWwZM95pG7j', 'object': 'thread.message', 'created_at': 1741592413, 'assistant_id': None, 'thread_id': 'thread_Y2Xq6HSTQgAbRnqneems8fqb', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': '    \\n               List out kubebernetes entities.\\n            ', 'annotations': []}}], 'attachments': [], 'metadata': {}}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "pprint(messages[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Kubernetes consists of various entities that play vital roles in managing containerized applications. Below is a list of some key Kubernetes entities:\n",
       "\n",
       "### 1. Workload Resources\n",
       "- **Pod**: A collection of one or more containers that share the same network namespace.\n",
       "- **ReplicaSet**: Ensures that a specified number of pod replicas are running at any given time.\n",
       "- **Deployment**: Manages the creation and updates of ReplicaSets and Pods in a declarative manner.\n",
       "- **StatefulSet**: Designed for managing stateful applications, it provides guarantees about the ordering and uniqueness of Pods.\n",
       "- **DaemonSet**: Ensures that a copy of a Pod runs on all or some nodes in the cluster.\n",
       "- **Job**: Represents a one-time task that runs a Pod until completion.\n",
       "- **CronJob**: Manages time-based jobs that run on a schedule.\n",
       "\n",
       "### 2. Service Resources\n",
       "- **Service**: An abstract way to expose an application running on a set of Pods as a network service.\n",
       "- **EndpointSlice**: Provides a link between Services and Pods for better scalability.\n",
       "\n",
       "### 3. Config and Storage Resources\n",
       "- **ConfigMap**: An API object used to store non-confidential data in key-value pairs.\n",
       "- **Secret**: Similar to ConfigMap but is specifically designed to hold sensitive data such as passwords or tokens.\n",
       "- **PersistentVolume (PV)**: A piece of storage in the cluster that has been provisioned by an administrator.\n",
       "- **PersistentVolumeClaim (PVC)**: A request for storage by a user.\n",
       "\n",
       "### 4. Policy Resources\n",
       "- **NetworkPolicy**: Defines rules for how Pods can communicate with each other and with other network endpoints.\n",
       "- **PodDisruptionBudget**: Specifies the minimum number of Pods that should be kept available during voluntary disruptions.\n",
       "\n",
       "### 5. Authentication and Authorization Resources\n",
       "- **ServiceAccount**: An account for processes running in a Pod.\n",
       "- **Role and ClusterRole**: Define access permissions for resources in a namespace (Role) or in the entire cluster (ClusterRole).\n",
       "- **RoleBinding and ClusterRoleBinding**: Bind roles to users or service accounts to grant them permissions defined in the respective roles.\n",
       "\n",
       "### 6. Extend Resources\n",
       "- **CustomResourceDefinition (CRD)**: Allows users to extend Kubernetes capabilities to create custom resources that are not part of the core Kubernetes API.\n",
       "\n",
       "### 7. Other Resources\n",
       "- **Namespace**: A way to divide cluster resources between multiple users (via resource quota).\n",
       "- **Event**: Records notable occurrences in the cluster.\n",
       "\n",
       "These entities interact with each other to form a robust structure for deploying and managing applications in Kubernetes【4:1†source】【4:2†source】."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "last_msg =  messages.get_last_text_message_by_role(\"assistant\")\n",
    "if last_msg:\n",
    "    display(Markdown(last_msg.text.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'file_citation', 'text': '【4:3†source】', 'start_index': 1812, 'end_index': 1824, 'file_citation': {'file_id': 'assistant-4Rb8C1gpvMCQiBXSXdJGMY'}},\n",
      " {'type': 'file_citation', 'text': '【4:4†source】', 'start_index': 1824, 'end_index': 1836, 'file_citation': {'file_id': 'assistant-SB1qhoEhyHrgLqYhZ5Pj7f'}},\n",
      " {'type': 'file_citation', 'text': '【4:5†source】', 'start_index': 1836, 'end_index': 1848, 'file_citation': {'file_id': 'assistant-4Rb8C1gpvMCQiBXSXdJGMY'}}]\n"
     ]
    }
   ],
   "source": [
    "pprint(last_msg.text.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent with ID: asst_vF0O9ZQe70AI9U9Nw9hLd2jn\n",
      "Deleted vector store with ID: vs_muuE7atPFSURXEgGF6YqfWl0\n",
      "Deleted settings.yaml file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(SETTINGS_FILE):\n",
    "    with open(SETTINGS_FILE, \"r\") as file:\n",
    "        settings = yaml.safe_load(file)\n",
    "\n",
    "    if \"agent_id\" in settings:\n",
    "        agent_id = settings[\"agent_id\"]\n",
    "        project_client.agents.delete_agent(agent_id)\n",
    "        print(f\"Deleted agent with ID: {agent_id}\")\n",
    "    else:\n",
    "        print(\"Agent ID not found in settings.\")\n",
    "\n",
    "    if \"vector_store_id\" in settings:\n",
    "        vector_store_id = settings[\"vector_store_id\"]\n",
    "        project_client.agents.delete_vector_store(vector_store_id)\n",
    "        print(f\"Deleted vector store with ID: {vector_store_id}\")\n",
    "    else:\n",
    "        print(\"Vector store ID not found in settings.\")\n",
    "    os.remove(SETTINGS_FILE)\n",
    "    os.remove(IMPORTED_FILES)\n",
    "    # os.remove(IMPORTED_FILE_IDS)\n",
    "    print(\"Deleted settings.yaml file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list', 'data': [], 'first_id': None, 'last_id': None, 'has_more': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_client.agents.list_vector_stores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = project_client.agents.list_files()\n",
    "for file in files[\"data\"]:\n",
    "    project_client.agents.delete_file(file.id)\n",
    "    print(f\"Deleted file with ID: {file.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
